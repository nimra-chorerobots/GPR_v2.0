# Physical-AI Subsurface Perception using GPR

This repository implements a Physical-AI perception stack for autonomous robots equipped with Ground-Penetrating Radar (GPR). 

The system allows robots to reason about buried hazards before physical interaction, enabling pre-emptive safety behavior instead of reactive collision avoidance. Therefore, this repository includes a live visualization interface that converts raw GPR signals into real-time subsurface perception displays, making underground hazards directly observable to operators and developers.


---

## ðŸ§  Perception Pipeline

GPR Antenna â†’ B-Scan Formation â†’ Feature Encoding â†’ Anomaly Detection â†’ Safety Supervisor â†’ Motion Constraint

---

## ðŸ“‚ Folder Structure

<img width="303" height="244" alt="image" src="https://github.com/user-attachments/assets/e3ce6a83-cefb-4459-9ca9-a6301cf4563b" />


---

## ðŸ“¦ Dataset

Download the dataset from Zenodo:

https://zenodo.org/records/14270869

Extract into:

<img width="245" height="186" alt="image" src="https://github.com/user-attachments/assets/a37c7d7b-8abf-4b1e-ab5a-5c3f23b13032" />

pip install numpy opencv-python


